{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Hearth-Stone-Python-Simulator/blob/main/Welcome_To_Colab_(5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S-_po4xqrjrV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, Embedding, Bidirectional, Attention, Concatenate, Masking\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import gc\n",
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5T7DysGQjIb",
        "outputId": "dab96332-d703-4b0b-c73b-82ab1f40e5dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bNk74K2xrlcM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"/content/drive/MyDrive/MTGdata/AtomicCards.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uRDWz2gErzRI"
      },
      "outputs": [],
      "source": [
        "def replace_card_name(index, text):\n",
        "  name_parts = index.split(',')  # Split by comma\n",
        "  possible_matches = [index]\n",
        "\n",
        "  # Add individual name parts if comma exists\n",
        "  if len(name_parts) > 1:\n",
        "    possible_matches.extend([part.strip() for part in name_parts])\n",
        "\n",
        "  # Add permutation for names with multiple words before comma\n",
        "  first_part = name_parts[0].strip()  # Get the part before comma\n",
        "  first_part_words = first_part.split()  # Split into words\n",
        "  if len(first_part_words) > 1:\n",
        "      possible_matches.append(first_part_words[0]) # Add the first word as a match\n",
        "\n",
        "  # Replace occurrences of possible matches in the text, using word boundaries\n",
        "  for name in possible_matches:\n",
        "    text = re.sub(r'\\b' + re.escape(name) + r'\\b', 'this', text) # Use re.escape and word boundaries\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Deo6Hcei0RWH"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "    text = re.sub(r'\\/', ' ', text)\n",
        "    text = re.sub(r'\\{|\\}', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s\\+\\-]', '', text)\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AcV0DPJ3sEgG"
      },
      "outputs": [],
      "source": [
        "text_list = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # Process the indices you're interested in: 0, 1, and 3\n",
        "    for data_index in [0, 1, 3, 4, 5, 6]:\n",
        "        try:\n",
        "            text = row['data'][data_index]['text']\n",
        "            text = replace_card_name(index, text)\n",
        "            text = clean_text(text)\n",
        "            text_list.append(text)\n",
        "        except:\n",
        "            pass  # Silently handle the exception\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E-P3eGNS9bW1"
      },
      "outputs": [],
      "source": [
        "# Assuming your list of strings is named 'text_list'\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_list)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert text to sequences\n",
        "input_sequences = tokenizer.texts_to_sequences(text_list)\n",
        "\n",
        "# Pad sequences to have the same length\n",
        "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
        "encoder_input_data = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Create decoder input data (shifted by one timestep) and decoder target data\n",
        "decoder_input_data = np.zeros_like(encoder_input_data)\n",
        "decoder_target_data = np.zeros_like(encoder_input_data)\n",
        "\n",
        "for i, seq in enumerate(encoder_input_data):\n",
        "  decoder_input_data[i, 1:] = seq[:-1]  # Shifted by one timestep\n",
        "  decoder_target_data[i, :-1] = seq[1:]  # Target is the original sequence without the start token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder model\n",
        "encoder_inputs = Input(shape=(max_sequence_length,))\n",
        "encoder_embedding = Embedding(total_words, 256)(encoder_inputs)\n",
        "encoder_lstm = LSTM(256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]  # Hidden and cell states\n",
        "\n",
        "# Define encoder model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "wy8wZHX_t_ck"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder model\n",
        "decoder_inputs = Input(shape=(max_sequence_length,))\n",
        "decoder_embedding = Embedding(total_words, 256)(decoder_inputs)\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_states = [decoder_state_h, decoder_state_c]\n",
        "\n",
        "decoder_dense = Dense(total_words, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define decoder model\n",
        "decoder_model = Model([decoder_inputs] + encoder_states, [decoder_outputs] + decoder_states)"
      ],
      "metadata": {
        "id": "kJCdzWf3uCyy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect the encoder and decoder\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=64, epochs=100, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZy5dQ_tuFGr",
        "outputId": "3b7bd6f6-ded0-40b5-ce91-cbb4b997437d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 65ms/step - accuracy: 0.8989 - loss: 1.1728 - val_accuracy: 0.9171 - val_loss: 0.4583\n",
            "Epoch 2/100\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.9227 - loss: 0.4228 - val_accuracy: 0.9295 - val_loss: 0.3798\n",
            "Epoch 3/100\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.9325 - loss: 0.3541 - val_accuracy: 0.9347 - val_loss: 0.3409\n",
            "Epoch 4/100\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.9380 - loss: 0.3157 - val_accuracy: 0.9377 - val_loss: 0.3182\n",
            "Epoch 5/100\n",
            "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.9404 - loss: 0.2961 - val_accuracy: 0.9400 - val_loss: 0.3013\n",
            "Epoch 6/100\n",
            "\u001b[1m 55/396\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 57ms/step - accuracy: 0.9431 - loss: 0.2770"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_string(input_string, encoder_model, tokenizer, max_sequence_length):\n",
        "  \"\"\"Encodes a string into a single vector representation.\n",
        "\n",
        "  Args:\n",
        "    input_string: The string to encode.\n",
        "    encoder_model: The trained encoder model.\n",
        "    tokenizer: The tokenizer used to convert the string to a sequence of token IDs.\n",
        "    max_sequence_length: The maximum sequence length used during training.\n",
        "\n",
        "  Returns:\n",
        "    A single vector representation of the input string.\n",
        "  \"\"\"\n",
        "  # Preprocess the string\n",
        "  cleaned_string = clean_text(input_string)\n",
        "  input_sequence = tokenizer.texts_to_sequences([cleaned_string])  # Wrap in a list\n",
        "  padded_sequence = pad_sequences(input_sequence, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "  # Encode using the encoder model\n",
        "  states = encoder_model.predict(padded_sequence)  # Get hidden and cell states\n",
        "  encoded_vector = np.concatenate(states, axis=-1)  # Concatenate states\n",
        "\n",
        "  return encoded_vector[0]  # Return the first element (since we only encoded one string)\n",
        "\n",
        "# Example usage\n",
        "string_to_encode = \"This is the string I want to encode.\"\n",
        "encoded_vector = encode_string(string_to_encode, encoder_model, tokenizer, max_sequence_length)\n",
        "\n",
        "print(\"Encoded vector:\", encoded_vector)  # To see the output, run the code."
      ],
      "metadata": {
        "id": "GD7YxGMKvYy_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}