{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Hearth-Stone-Python-Simulator/blob/main/Welcome_To_Colab_(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "S-_po4xqrjrV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, Embedding, Bidirectional, Attention, Concatenate, Masking\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import gc\n",
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bNk74K2xrlcM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"/content/AtomicCards.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uRDWz2gErzRI"
      },
      "outputs": [],
      "source": [
        "def replace_card_name(index, text):\n",
        "  name_parts = index.split(',')  # Split by comma\n",
        "  possible_matches = [index]\n",
        "\n",
        "  # Add individual name parts if comma exists\n",
        "  if len(name_parts) > 1:\n",
        "    possible_matches.extend([part.strip() for part in name_parts])\n",
        "\n",
        "  # Add permutation for names with multiple words before comma\n",
        "  first_part = name_parts[0].strip()  # Get the part before comma\n",
        "  first_part_words = first_part.split()  # Split into words\n",
        "  if len(first_part_words) > 1:\n",
        "      possible_matches.append(first_part_words[0]) # Add the first word as a match\n",
        "\n",
        "  # Replace occurrences of possible matches in the text, using word boundaries\n",
        "  for name in possible_matches:\n",
        "    text = re.sub(r'\\b' + re.escape(name) + r'\\b', 'this', text) # Use re.escape and word boundaries\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Deo6Hcei0RWH"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "    text = re.sub(r'\\/', ' ', text)\n",
        "    text = re.sub(r'\\{|\\}', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s\\+\\-]', '', text)\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AcV0DPJ3sEgG"
      },
      "outputs": [],
      "source": [
        "text_list = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # Process the indices you're interested in: 0, 1, and 3\n",
        "    for data_index in [0, 1, 3, 4, 5, 6]:\n",
        "        try:\n",
        "            text = row['data'][data_index]['text']\n",
        "            text = replace_card_name(index, text)\n",
        "            text = clean_text(text)\n",
        "            text_list.append(\"<START> \" + text + \" <END>\")\n",
        "        except:\n",
        "            pass  # Silently handle the exception\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-P3eGNS9bW1",
        "outputId": "e96b8e20-9f07-48e5-b9c2-7d3a88fb4ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31634\n"
          ]
        }
      ],
      "source": [
        "print(len(text_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "kKDQVbNR9bW1",
        "outputId": "19ba905a-8e1e-496c-f5a1-135942c011ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 4409\n",
            "START token ID: None\n",
            "END token ID: None\n",
            "Maximum sequence length: 253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'embedding_5' (of type Embedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ masking_5 (\u001b[38;5;33mMasking\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m1,322,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_7 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │         \u001b[38;5;34m602,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)                │      \u001b[38;5;34m32,008,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_5 (\u001b[38;5;33mRepeatVector\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │      \u001b[38;5;34m32,008,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_8 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m4409\u001b[0m)           │       \u001b[38;5;34m8,822,409\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ masking_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,322,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">602,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">32,008,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">32,008,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4409</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,822,409</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m74,763,109\u001b[0m (285.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,763,109</span> (285.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m74,763,109\u001b[0m (285.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,763,109</span> (285.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 2: Configure tokenizer with special tokens\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "# Add special tokens to ensure they're in the vocabulary\n",
        "tokenizer.fit_on_texts(text_list)\n",
        "\n",
        "# Add special token indices manually if needed\n",
        "word_index = tokenizer.word_index\n",
        "# Make sure special tokens have specific indices\n",
        "# This step is optional as they should already be in the vocabulary\n",
        "start_token_id = word_index.get(\"<START>\")\n",
        "end_token_id = word_index.get(\"<END>\")\n",
        "pad_token_id = 0  # Padding token is usually 0\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "print(f\"START token ID: {start_token_id}\")\n",
        "print(f\"END token ID: {end_token_id}\")\n",
        "\n",
        "# Convert to sequences\n",
        "sequences = tokenizer.texts_to_sequences(text_list)\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "print(f\"Maximum sequence length: {max_sequence_length}\")\n",
        "\n",
        "# Pad sequences\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Step 3: Define an improved LSTM Autoencoder model with masking\n",
        "def create_word_level_lstm_autoencoder(vocab_size, max_length, embedding_dim, latent_dim, pad_token_id=0):\n",
        "    # Define encoder\n",
        "    inputs = Input(shape=(max_length,))\n",
        "\n",
        "    # Add masking layer to ignore padding tokens\n",
        "    masked_inputs = Masking(mask_value=pad_token_id)(inputs)\n",
        "\n",
        "    x = Embedding(vocab_size, embedding_dim, input_length=max_length)(masked_inputs)\n",
        "    x = TimeDistributed(Dense(latent_dim, activation='relu'))(x)\n",
        "    encoded = LSTM(latent_dim)(x)\n",
        "\n",
        "    # Define decoder\n",
        "    decoded = RepeatVector(max_length)(encoded)\n",
        "    decoded = LSTM(latent_dim, return_sequences=True)(decoded)\n",
        "    decoded = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoded)\n",
        "\n",
        "    # Create autoencoder model\n",
        "    autoencoder = Model(inputs, decoded)\n",
        "    autoencoder.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Create encoder model for extracting embeddings later if needed\n",
        "    encoder_model = Model(inputs, encoded)\n",
        "\n",
        "    return autoencoder, encoder_model\n",
        "\n",
        "# Step 4: Create and train the model\n",
        "embedding_dim = 300\n",
        "latent_dim = 2000\n",
        "model, encoder = create_word_level_lstm_autoencoder(\n",
        "    vocab_size,\n",
        "    max_sequence_length,\n",
        "    embedding_dim,\n",
        "    latent_dim,\n",
        "    pad_token_id=0\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Step 5: Prepare target data with masking for training\n",
        "# Reshape target data for sparse categorical crossentropy\n",
        "target_data = np.expand_dims(padded_sequences, -1)\n",
        "\n",
        "# Create a mask to ignore padding tokens in the loss calculation\n",
        "# This is handled automatically by the Masking layer in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2J1Sxvd9bW2",
        "outputId": "85cc2fe1-dce7-4dc2-9341-0305276ec5fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 201ms/step - accuracy: 0.9030 - loss: 0.6763 - val_accuracy: 0.9095 - val_loss: 0.5735 - learning_rate: 0.0010\n",
            "Epoch 2/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9081 - loss: 0.5709 - val_accuracy: 0.9095 - val_loss: 0.5992 - learning_rate: 0.0010\n",
            "Epoch 3/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9075 - loss: 0.5738 - val_accuracy: 0.9095 - val_loss: 0.5718 - learning_rate: 0.0010\n",
            "Epoch 4/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9076 - loss: 0.5730 - val_accuracy: 0.9095 - val_loss: 0.5735 - learning_rate: 0.0010\n",
            "Epoch 5/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9075 - loss: 0.5732 - val_accuracy: 0.9095 - val_loss: 0.5749 - learning_rate: 0.0010\n",
            "Epoch 6/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9074 - loss: 0.5738 - val_accuracy: 0.9095 - val_loss: 0.5652 - learning_rate: 0.0010\n",
            "Epoch 7/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9070 - loss: 0.5760 - val_accuracy: 0.9095 - val_loss: 0.5761 - learning_rate: 0.0010\n",
            "Epoch 8/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9074 - loss: 0.5731 - val_accuracy: 0.9095 - val_loss: 0.5677 - learning_rate: 0.0010\n",
            "Epoch 9/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9075 - loss: 0.5721 - val_accuracy: 0.9095 - val_loss: 0.5648 - learning_rate: 0.0010\n",
            "Epoch 10/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9074 - loss: 0.5722 - val_accuracy: 0.9095 - val_loss: 0.5668 - learning_rate: 0.0010\n",
            "Epoch 11/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9077 - loss: 0.5718 - val_accuracy: 0.9095 - val_loss: 0.5647 - learning_rate: 0.0010\n",
            "Epoch 12/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9078 - loss: 0.5700 - val_accuracy: 0.9095 - val_loss: 0.5657 - learning_rate: 0.0010\n",
            "Epoch 13/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9074 - loss: 0.5727 - val_accuracy: 0.9095 - val_loss: 0.5641 - learning_rate: 0.0010\n",
            "Epoch 14/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9078 - loss: 0.5697 - val_accuracy: 0.9095 - val_loss: 0.5681 - learning_rate: 0.0010\n",
            "Epoch 15/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9076 - loss: 0.5710 - val_accuracy: 0.9095 - val_loss: 0.5670 - learning_rate: 0.0010\n",
            "Epoch 16/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9073 - loss: 0.5739\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9073 - loss: 0.5739 - val_accuracy: 0.9095 - val_loss: 0.5661 - learning_rate: 0.0010\n",
            "Epoch 17/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 197ms/step - accuracy: 0.9071 - loss: 0.5700 - val_accuracy: 0.9095 - val_loss: 0.5625 - learning_rate: 2.0000e-04\n",
            "Epoch 18/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 198ms/step - accuracy: 0.9075 - loss: 0.5679 - val_accuracy: 0.9095 - val_loss: 0.5663 - learning_rate: 2.0000e-04\n",
            "Epoch 19/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9074 - loss: 0.5671 - val_accuracy: 0.9095 - val_loss: 0.5627 - learning_rate: 2.0000e-04\n",
            "Epoch 20/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9074 - loss: 0.5609 - val_accuracy: 0.9104 - val_loss: 0.4727 - learning_rate: 2.0000e-04\n",
            "Epoch 21/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9099 - loss: 0.4768 - val_accuracy: 0.9153 - val_loss: 0.4586 - learning_rate: 2.0000e-04\n",
            "Epoch 22/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9125 - loss: 0.4646 - val_accuracy: 0.9158 - val_loss: 0.4550 - learning_rate: 2.0000e-04\n",
            "Epoch 23/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9134 - loss: 0.4607 - val_accuracy: 0.9161 - val_loss: 0.4505 - learning_rate: 2.0000e-04\n",
            "Epoch 24/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9132 - loss: 0.4594 - val_accuracy: 0.9159 - val_loss: 0.4492 - learning_rate: 2.0000e-04\n",
            "Epoch 25/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9135 - loss: 0.4564 - val_accuracy: 0.9158 - val_loss: 0.4481 - learning_rate: 2.0000e-04\n",
            "Epoch 26/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 198ms/step - accuracy: 0.9133 - loss: 0.4573 - val_accuracy: 0.9146 - val_loss: 0.4557 - learning_rate: 2.0000e-04\n",
            "Epoch 27/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 198ms/step - accuracy: 0.9137 - loss: 0.4547 - val_accuracy: 0.9166 - val_loss: 0.4456 - learning_rate: 2.0000e-04\n",
            "Epoch 28/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9133 - loss: 0.4577 - val_accuracy: 0.9166 - val_loss: 0.4444 - learning_rate: 2.0000e-04\n",
            "Epoch 29/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 198ms/step - accuracy: 0.9143 - loss: 0.4512 - val_accuracy: 0.9153 - val_loss: 0.4490 - learning_rate: 2.0000e-04\n",
            "Epoch 30/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9139 - loss: 0.4529 - val_accuracy: 0.9163 - val_loss: 0.4496 - learning_rate: 2.0000e-04\n",
            "Epoch 31/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9146 - loss: 0.4497 - val_accuracy: 0.9167 - val_loss: 0.4433 - learning_rate: 2.0000e-04\n",
            "Epoch 32/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 198ms/step - accuracy: 0.9138 - loss: 0.4539 - val_accuracy: 0.9163 - val_loss: 0.4484 - learning_rate: 2.0000e-04\n",
            "Epoch 33/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9148 - loss: 0.4486 - val_accuracy: 0.9165 - val_loss: 0.4454 - learning_rate: 2.0000e-04\n",
            "Epoch 34/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9143 - loss: 0.4515\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9143 - loss: 0.4515 - val_accuracy: 0.9142 - val_loss: 0.4524 - learning_rate: 2.0000e-04\n",
            "Epoch 35/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9152 - loss: 0.4484 - val_accuracy: 0.9175 - val_loss: 0.4405 - learning_rate: 4.0000e-05\n",
            "Epoch 36/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9156 - loss: 0.4455 - val_accuracy: 0.9174 - val_loss: 0.4404 - learning_rate: 4.0000e-05\n",
            "Epoch 37/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9152 - loss: 0.4469 - val_accuracy: 0.9175 - val_loss: 0.4397 - learning_rate: 4.0000e-05\n",
            "Epoch 38/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9149 - loss: 0.4482 - val_accuracy: 0.9176 - val_loss: 0.4395 - learning_rate: 4.0000e-05\n",
            "Epoch 39/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 198ms/step - accuracy: 0.9158 - loss: 0.4426 - val_accuracy: 0.9175 - val_loss: 0.4395 - learning_rate: 4.0000e-05\n",
            "Epoch 40/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9152 - loss: 0.4461 - val_accuracy: 0.9176 - val_loss: 0.4394 - learning_rate: 4.0000e-05\n",
            "Epoch 41/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9154 - loss: 0.4448 - val_accuracy: 0.9176 - val_loss: 0.4392 - learning_rate: 4.0000e-05\n",
            "Epoch 42/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9151 - loss: 0.4464 - val_accuracy: 0.9154 - val_loss: 0.4496 - learning_rate: 4.0000e-05\n",
            "Epoch 43/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9153 - loss: 0.4458 - val_accuracy: 0.9175 - val_loss: 0.4394 - learning_rate: 4.0000e-05\n",
            "Epoch 44/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9153 - loss: 0.4452 - val_accuracy: 0.9176 - val_loss: 0.4387 - learning_rate: 4.0000e-05\n",
            "Epoch 45/45\n",
            "\u001b[1m1780/1780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 198ms/step - accuracy: 0.9149 - loss: 0.4478 - val_accuracy: 0.9176 - val_loss: 0.4385 - learning_rate: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Create a callback that reduces the learning rate when a metric has stopped improving\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    factor=0.2,          # Factor by which the learning rate will be reduced\n",
        "    patience=3,          # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    min_lr=0.00001,      # Lower bound on the learning rate\n",
        "    verbose=1            # Print message when reducing learning rate\n",
        ")\n",
        "\n",
        "# Train the model with the learning rate reduction callback\n",
        "history = model.fit(\n",
        "    padded_sequences, target_data,\n",
        "    epochs=45,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    validation_split=0.1,\n",
        "    verbose=1,\n",
        "    callbacks=[reduce_lr]  # Add the callback\n",
        ")\n",
        "\n",
        "# Save the model in HDF5 format\n",
        "model.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "SaiDGQl59bW2",
        "outputId": "5d9f4763-9a83-4e3f-98f3-61b5a4c6a72c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making predictions on a small subset...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'padded_sequences' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5758ff85603>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Select only a few samples to evaluate (to avoid memory issues)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnum_samples_to_evaluate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Evaluate at most 3 examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# For reproducibility, you might want to set a seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'padded_sequences' is not defined"
          ]
        }
      ],
      "source": [
        "# Step 4: Evaluate the model on just a few examples\n",
        "print(\"Making predictions on a small subset...\")\n",
        "\n",
        "# Select only a few samples to evaluate (to avoid memory issues)\n",
        "num_samples_to_evaluate = min(3, len(padded_sequences))  # Evaluate at most 3 examples\n",
        "\n",
        "# For reproducibility, you might want to set a seed\n",
        "np.random.seed(42)\n",
        "sample_indices = np.random.choice(len(padded_sequences), num_samples_to_evaluate, replace=False)\n",
        "\n",
        "# Get the subset of data to evaluate\n",
        "subset_to_evaluate = padded_sequences[sample_indices]\n",
        "\n",
        "# Make predictions on the subset\n",
        "reconstructed_sequences = model.predict(subset_to_evaluate)\n",
        "\n",
        "# Convert probability distributions to token indices\n",
        "reconstructed_indices = np.argmax(reconstructed_sequences, axis=-1)\n",
        "\n",
        "# Function to convert indices back to text\n",
        "def indices_to_text(sequences, tokenizer):\n",
        "    index_word = {v: k for k, v in tokenizer.word_index.items()}\n",
        "    index_word[0] = ''  # Padding token\n",
        "    texts = []\n",
        "    for seq in sequences:\n",
        "        # Filter out padding tokens and join words\n",
        "        words = [index_word.get(idx, '<UNK>') for idx in seq if idx > 0]\n",
        "        text = ' '.join(words).strip()\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "# Display results\n",
        "original_texts = [text_list[i] for i in sample_indices]  # Get original texts for selected indices\n",
        "reconstructed_texts = indices_to_text(reconstructed_indices, tokenizer)\n",
        "\n",
        "print(\"\\nOriginal vs Reconstructed:\")\n",
        "for i, (orig, recon) in enumerate(zip(original_texts, reconstructed_texts)):\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"Original: {orig}\")\n",
        "    print(f\"Reconstructed: {recon}\")\n",
        "\n",
        "    # Calculate and display word-level accuracy\n",
        "    orig_tokens = orig.split()\n",
        "    recon_tokens = recon.split()\n",
        "    min_len = min(len(orig_tokens), len(recon_tokens))\n",
        "\n",
        "    if min_len > 0:\n",
        "        matches = sum(1 for i in range(min_len) if orig_tokens[i] == recon_tokens[i])\n",
        "        accuracy = matches / len(orig_tokens) if len(orig_tokens) > 0 else 0\n",
        "        print(f\"Word-level accuracy: {accuracy:.2f} ({matches}/{len(orig_tokens)} words matched)\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}