{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Hearth-Stone-Python-Simulator/blob/main/mtg%20auto%20encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S-_po4xqrjrV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, Embedding, Bidirectional, Attention, Concatenate, Masking\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import gc\n",
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bNk74K2xrlcM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"/content/drive/MyDrive/MTGdata/AtomicCards.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZbdSWrZ6cHu",
        "outputId": "15575824-da11-4093-fad9-e9d6dd3f1e85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uRDWz2gErzRI"
      },
      "outputs": [],
      "source": [
        "def replace_card_name(index, text):\n",
        "  name_parts = index.split(',')  # Split by comma\n",
        "  possible_matches = [index]\n",
        "\n",
        "  # Add individual name parts if comma exists\n",
        "  if len(name_parts) > 1:\n",
        "    possible_matches.extend([part.strip() for part in name_parts])\n",
        "\n",
        "  # Add permutation for names with multiple words before comma\n",
        "  first_part = name_parts[0].strip()  # Get the part before comma\n",
        "  first_part_words = first_part.split()  # Split into words\n",
        "  if len(first_part_words) > 1:\n",
        "      possible_matches.append(first_part_words[0]) # Add the first word as a match\n",
        "\n",
        "  # Replace occurrences of possible matches in the text, using word boundaries\n",
        "  for name in possible_matches:\n",
        "    text = re.sub(r'\\b' + re.escape(name) + r'\\b', 'this', text) # Use re.escape and word boundaries\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Deo6Hcei0RWH"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "    text = re.sub(r'\\/', ' ', text)\n",
        "    text = re.sub(r'\\{|\\}', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s\\+\\-]', '', text)\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AcV0DPJ3sEgG"
      },
      "outputs": [],
      "source": [
        "text_list = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # Process the indices you're interested in: 0, 1, and 3\n",
        "    for data_index in [0, 1, 3, 4, 5, 6]:\n",
        "        try:\n",
        "            text = row['data'][data_index]['text']\n",
        "            text = replace_card_name(index, text)\n",
        "            text = clean_text(text)\n",
        "            text_list.append(\"<START> \" + text + \" <END>\")\n",
        "        except:\n",
        "            pass  # Silently handle the exception\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-P3eGNS9bW1",
        "outputId": "e96b8e20-9f07-48e5-b9c2-7d3a88fb4ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31634\n"
          ]
        }
      ],
      "source": [
        "print(len(text_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "kKDQVbNR9bW1",
        "outputId": "19ba905a-8e1e-496c-f5a1-135942c011ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 4409\n",
            "START token ID: None\n",
            "END token ID: None\n",
            "Maximum sequence length: 253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'embedding_5' (of type Embedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ masking_5 (\u001b[38;5;33mMasking\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m1,322,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_7 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │         \u001b[38;5;34m602,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)                │      \u001b[38;5;34m32,008,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_5 (\u001b[38;5;33mRepeatVector\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │      \u001b[38;5;34m32,008,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_8 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m4409\u001b[0m)           │       \u001b[38;5;34m8,822,409\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ masking_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,322,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">602,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">32,008,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">32,008,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4409</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,822,409</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m74,763,109\u001b[0m (285.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,763,109</span> (285.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m74,763,109\u001b[0m (285.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,763,109</span> (285.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 2: Configure tokenizer with special tokens\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "# Add special tokens to ensure they're in the vocabulary\n",
        "tokenizer.fit_on_texts(text_list)\n",
        "\n",
        "# Add special token indices manually if needed\n",
        "word_index = tokenizer.word_index\n",
        "# Make sure special tokens have specific indices\n",
        "# This step is optional as they should already be in the vocabulary\n",
        "start_token_id = word_index.get(\"<START>\")\n",
        "end_token_id = word_index.get(\"<END>\")\n",
        "pad_token_id = 0  # Padding token is usually 0\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "print(f\"START token ID: {start_token_id}\")\n",
        "print(f\"END token ID: {end_token_id}\")\n",
        "\n",
        "# Convert to sequences\n",
        "sequences = tokenizer.texts_to_sequences(text_list)\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "print(f\"Maximum sequence length: {max_sequence_length}\")\n",
        "\n",
        "# Pad sequences\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Step 3: Define an improved LSTM Autoencoder model with masking\n",
        "def create_word_level_lstm_autoencoder(vocab_size, max_length, embedding_dim, latent_dim, pad_token_id=0):\n",
        "    # Define encoder\n",
        "    inputs = Input(shape=(max_length,))\n",
        "\n",
        "    # Add masking layer to ignore padding tokens\n",
        "    masked_inputs = Masking(mask_value=pad_token_id)(inputs)\n",
        "\n",
        "    x = Embedding(vocab_size, embedding_dim, input_length=max_length)(masked_inputs)\n",
        "    x = TimeDistributed(Dense(latent_dim, activation='relu'))(x)\n",
        "    encoded = LSTM(latent_dim)(x)\n",
        "\n",
        "    # Define decoder\n",
        "    decoded = RepeatVector(max_length)(encoded)\n",
        "    decoded = LSTM(latent_dim, return_sequences=True)(decoded)\n",
        "    decoded = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoded)\n",
        "\n",
        "    # Create autoencoder model\n",
        "    autoencoder = Model(inputs, decoded)\n",
        "    autoencoder.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Create encoder model for extracting embeddings later if needed\n",
        "    encoder_model = Model(inputs, encoded)\n",
        "\n",
        "    return autoencoder, encoder_model\n",
        "\n",
        "# Step 4: Create and train the model\n",
        "embedding_dim = 300\n",
        "latent_dim = 2000\n",
        "model, encoder = create_word_level_lstm_autoencoder(\n",
        "    vocab_size,\n",
        "    max_sequence_length,\n",
        "    embedding_dim,\n",
        "    latent_dim,\n",
        "    pad_token_id=0\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Step 5: Prepare target data with masking for training\n",
        "# Reshape target data for sparse categorical crossentropy\n",
        "target_data = np.expand_dims(padded_sequences, -1)\n",
        "\n",
        "# Create a mask to ignore padding tokens in the loss calculation\n",
        "# This is handled automatically by the Masking layer in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "n2J1Sxvd9bW2",
        "outputId": "37bdd5c6-c7a8-44ab-f464-af85f573965f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ReduceLROnPlateau' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2a43d7a53627>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a callback that reduces the learning rate when a metric has stopped improving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m reduce_lr = ReduceLROnPlateau(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Monitor validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# Factor by which the learning rate will be reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# Number of epochs with no improvement after which learning rate will be reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ReduceLROnPlateau' is not defined"
          ]
        }
      ],
      "source": [
        "# Create a callback that reduces the learning rate when a metric has stopped improving\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    factor=0.2,          # Factor by which the learning rate will be reduced\n",
        "    patience=3,          # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    min_lr=0.00001,      # Lower bound on the learning rate\n",
        "    verbose=1            # Print message when reducing learning rate\n",
        ")\n",
        "\n",
        "# Train the model with the learning rate reduction callback\n",
        "history = model.fit(\n",
        "    padded_sequences, target_data,\n",
        "    epochs=45,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    validation_split=0.1,\n",
        "    verbose=1,\n",
        "    callbacks=[reduce_lr]  # Add the callback\n",
        ")\n",
        "\n",
        "# Save the model in HDF5 format\n",
        "model.save('/content/drive/MyDrive/GeneratedData')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "SaiDGQl59bW2",
        "outputId": "5d9f4763-9a83-4e3f-98f3-61b5a4c6a72c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making predictions on a small subset...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'padded_sequences' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5758ff85603>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Select only a few samples to evaluate (to avoid memory issues)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnum_samples_to_evaluate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Evaluate at most 3 examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# For reproducibility, you might want to set a seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'padded_sequences' is not defined"
          ]
        }
      ],
      "source": [
        "# Step 4: Evaluate the model on just a few examples\n",
        "print(\"Making predictions on a small subset...\")\n",
        "\n",
        "# Select only a few samples to evaluate (to avoid memory issues)\n",
        "num_samples_to_evaluate = min(3, len(padded_sequences))  # Evaluate at most 3 examples\n",
        "\n",
        "# For reproducibility, you might want to set a seed\n",
        "np.random.seed(42)\n",
        "sample_indices = np.random.choice(len(padded_sequences), num_samples_to_evaluate, replace=False)\n",
        "\n",
        "# Get the subset of data to evaluate\n",
        "subset_to_evaluate = padded_sequences[sample_indices]\n",
        "\n",
        "# Make predictions on the subset\n",
        "reconstructed_sequences = model.predict(subset_to_evaluate)\n",
        "\n",
        "# Convert probability distributions to token indices\n",
        "reconstructed_indices = np.argmax(reconstructed_sequences, axis=-1)\n",
        "\n",
        "# Function to convert indices back to text\n",
        "def indices_to_text(sequences, tokenizer):\n",
        "    index_word = {v: k for k, v in tokenizer.word_index.items()}\n",
        "    index_word[0] = ''  # Padding token\n",
        "    texts = []\n",
        "    for seq in sequences:\n",
        "        # Filter out padding tokens and join words\n",
        "        words = [index_word.get(idx, '<UNK>') for idx in seq if idx > 0]\n",
        "        text = ' '.join(words).strip()\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "# Display results\n",
        "original_texts = [text_list[i] for i in sample_indices]  # Get original texts for selected indices\n",
        "reconstructed_texts = indices_to_text(reconstructed_indices, tokenizer)\n",
        "\n",
        "print(\"\\nOriginal vs Reconstructed:\")\n",
        "for i, (orig, recon) in enumerate(zip(original_texts, reconstructed_texts)):\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"Original: {orig}\")\n",
        "    print(f\"Reconstructed: {recon}\")\n",
        "\n",
        "    # Calculate and display word-level accuracy\n",
        "    orig_tokens = orig.split()\n",
        "    recon_tokens = recon.split()\n",
        "    min_len = min(len(orig_tokens), len(recon_tokens))\n",
        "\n",
        "    if min_len > 0:\n",
        "        matches = sum(1 for i in range(min_len) if orig_tokens[i] == recon_tokens[i])\n",
        "        accuracy = matches / len(orig_tokens) if len(orig_tokens) > 0 else 0\n",
        "        print(f\"Word-level accuracy: {accuracy:.2f} ({matches}/{len(orig_tokens)} words matched)\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}